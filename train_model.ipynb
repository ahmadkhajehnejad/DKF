{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model import Model\n",
    "import os\n",
    "from pykalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data.txt') as f:\n",
    "    first = f.readline()\n",
    "    first = first.strip('\\n')\n",
    "    temp = first.split(' ')\n",
    "    T = int(temp[0])\n",
    "    o_dim = int(temp[1])\n",
    "    s_dim = int(temp[2])\n",
    "    o_matrix = np.zeros((T, o_dim), np.float32)\n",
    "    for i in range(T):\n",
    "        temp = f.readline().strip('\\n').split(' ')\n",
    "        for j in range(s_dim):\n",
    "            o_matrix[i,j] = float(temp[j])\n",
    "    s_matrix = np.zeros((T, s_dim), np.float32)\n",
    "    for i in range(T):\n",
    "        temp = f.readline().strip('\\n').split(' ')\n",
    "        for j in range(o_dim):\n",
    "            s_matrix[i,j] = float(temp[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = 2000\n",
    "h_dim = 10\n",
    "train_data = np.zeros((int(T/2), 3*s_dim), np.float32)\n",
    "for i in range(int(T/2)):\n",
    "    train_data[i, :] = np.concatenate((s_matrix[i, :], s_matrix[i+1, :], o_matrix[i+1, :]), axis=0)\n",
    "test_data = np.zeros((int(T/2) - 1, 3*s_dim), np.float32)\n",
    "for i in range(int(T/2) - 1):\n",
    "    test_data[i, :] = np.concatenate((s_matrix[int(T/2) + i, :], s_matrix[int(T/2) + 1 + i, :], o_matrix[int(T/2) + 1 + i, :]),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, train, test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "    def random_batch(self, batch_size):\n",
    "        index = np.random.choice(np.arange(len(self.train)),batch_size, False)\n",
    "        return self.train[index,:]\n",
    "dataset = Dataset(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 900,\trecons loss: 250.7180,\tlikelihood: 2540287.9455,\tclass loss: 2.3918\n",
      "step: 1800,\trecons loss: 155.1894,\tlikelihood: 33900280.4292,\tclass loss: 1.4330\n",
      "step: 2700,\trecons loss: 41.2168,\tlikelihood: 122120881.5600,\tclass loss: 1.6313\n",
      "step: 3600,\trecons loss: 27.2019,\tlikelihood: 62764556.5917,\tclass loss: 1.2392\n",
      "step: 4500,\trecons loss: 27.2755,\tlikelihood: 44404715.3875,\tclass loss: 1.6019\n",
      "step: 5400,\trecons loss: 27.1946,\tlikelihood: 13228010.4481,\tclass loss: 1.2943\n",
      "step: 6300,\trecons loss: 27.2388,\tlikelihood: 4981054.8861,\tclass loss: 1.6205\n",
      "step: 7200,\trecons loss: 27.3754,\tlikelihood: 4421733.8765,\tclass loss: 1.4930\n",
      "step: 8100,\trecons loss: 27.4860,\tlikelihood: 906193.7030,\tclass loss: 1.5911\n",
      "step: 9000,\trecons loss: 28.8203,\tlikelihood: 1274219.1916,\tclass loss: 2.0031\n",
      "step: 9900,\trecons loss: 31.0698,\tlikelihood: 6004064.3356,\tclass loss: 2.1690\n",
      "step: 10800,\trecons loss: 30.2723,\tlikelihood: 3141571.3080,\tclass loss: 1.9431\n",
      "step: 11700,\trecons loss: 33.0502,\tlikelihood: 2227098.1418,\tclass loss: 2.2924\n",
      "step: 12600,\trecons loss: 30.4578,\tlikelihood: 1497215.0326,\tclass loss: 2.2442\n",
      "step: 13500,\trecons loss: 32.1590,\tlikelihood: 1820283.3520,\tclass loss: 2.6915\n",
      "step: 14400,\trecons loss: 30.5569,\tlikelihood: 1450129.7910,\tclass loss: 2.4595\n",
      "step: 15300,\trecons loss: 31.7983,\tlikelihood: 592614.2266,\tclass loss: 2.4076\n",
      "step: 16200,\trecons loss: 36.2768,\tlikelihood: 1757132.0565,\tclass loss: 2.4479\n"
     ]
    }
   ],
   "source": [
    "log_dir = './log/'\n",
    "os.popen('rm '+log_dir+'*')\n",
    "minibatch_size = 128\n",
    "model = Model(s_dim, h_dim, minibatch_size, 1e-4, log_dir)\n",
    "iteration = 300\n",
    "for epoch in range(84):\n",
    "    reconstruction_loss_train, likelihood_train, classify_loss_train = 0., 0., 0.\n",
    "    global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "    # in each epoch 500 iterations\n",
    "    for i in range(iteration):\n",
    "        reconstruction_loss_value, likelihood_value, classify_loss_value, summary = \\\n",
    "                model.update_params(dataset.random_batch(minibatch_size))\n",
    "            \n",
    "        reconstruction_loss_train += reconstruction_loss_value\n",
    "        likelihood_train += likelihood_value\n",
    "        classify_loss_train += classify_loss_value\n",
    "        model.train_writer.add_summary(summary, global_step.eval(model.sess))\n",
    "    \n",
    "    reconstruction_loss_train = reconstruction_loss_train / (iteration)\n",
    "    likelihood_train = -likelihood_train / (iteration)\n",
    "    classify_loss_train = classify_loss_train / (iteration)\n",
    "    \n",
    "\n",
    "    print(\"step: {},\\trecons loss: {:.4f},\\tlikelihood: {:.4f},\\tclass loss: {:.4f}\".format(global_step.eval(model.sess),\n",
    "            reconstruction_loss_train, likelihood_train, classify_loss_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_s_p = np.asarray(model.sess.run([model.s_t_p], {model.input_tensor: train_data[train_data.shape[0]-2 : ,:]}))[0][1,:]\n",
    "\n",
    "a_2, b_2, sig_2, a_3, b_3, sig_3 = model.sess.run([model.a_2, model.b_2, model.sigma_2,\\\n",
    "                                                    model.a_3, model.b_3, model.sigma_3],\\\n",
    "                                                   {model.input_tensor: train_data}\\\n",
    "                                                  )\n",
    "kf = KalmanFilter(initial_state_mean = np.transpose(np.matmul(last_s_p,a_2) + b_2), \\\n",
    "                  initial_state_covariance = sig_2, \\\n",
    "                  transition_matrices = np.transpose(a_2), \\\n",
    "                  transition_offsets = b_2,\n",
    "                  transition_covariance = sig_2, \\\n",
    "                  observation_matrices = np.transpose(a_3),\\\n",
    "                  observation_offsets = b_3,\n",
    "                  observation_covariance = sig_3)\n",
    "est_o_t_p = model.sess.run(model.o_t_p, {model.input_tensor: test_data})\n",
    "measurements = np.asarray(est_o_t_p)\n",
    "(est_s_t_p, est_s_t_p_covariances) = kf.filter(measurements)\n",
    "est_s_t = model.decode_s_t_p(est_s_t_p)\n",
    "print(np.mean(np.linalg.norm(est_s_t - test_data[:, s_dim : 2*s_dim] , axis = 1)), end = '')\n",
    "print(' / ', end = '')\n",
    "print(np.mean(np.linalg.norm(test_data[:, s_dim : 2*s_dim], axis = 1)))\n",
    "print('mean consecutive diff: ', end='')\n",
    "print(np.mean(np.linalg.norm(test_data[1:, s_dim : 2*s_dim] - test_data[:-1, s_dim : 2*s_dim], axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_T = train_data.shape[0]\n",
    "s_t_minus_1_train = train_data[:,:s_dim]\n",
    "s_t_train = train_data[:,s_dim:2*s_dim]\n",
    "\n",
    "sumStSt_1 = np.sum(\\\n",
    "                   np.matmul(\\\n",
    "                             np.reshape(s_t_train, [-1,s_dim,1]),\\\n",
    "                             np.reshape(s_t_minus_1_train, [-1,1,s_dim])\\\n",
    "                            ),axis=0\\\n",
    "                  )\n",
    "sumSt_1 = np.transpose(np.sum(s_t_minus_1_train, axis=0, keepdims=True))\n",
    "sumSt = np.transpose(np.sum(s_t_train,axis=0,keepdims=True))\n",
    "sumSt_1St_1 =np.sum(\\\n",
    "                    np.matmul(\\\n",
    "                              np.reshape(s_t_minus_1_train, [-1,s_dim,1]),\\\n",
    "                              np.reshape(s_t_minus_1_train, [-1,1,s_dim])\\\n",
    "                             ),axis=0\\\n",
    "                   )\n",
    "\n",
    "A_2 = np.matmul(\\\n",
    "                sumStSt_1 - (np.matmul(sumSt, np.transpose(sumSt_1)) / train_T),\\\n",
    "                np.linalg.inv(\\\n",
    "                              sumSt_1St_1 - (np.matmul(sumSt_1, np.transpose(sumSt_1)) / train_T)\n",
    "                             )\\\n",
    "               )\n",
    "b_2 = (sumSt - np.matmul(A_2, sumSt_1)) / train_T\n",
    "\n",
    "tmp = s_t_train - np.matmul(s_t_minus_1_train, np.transpose(A_2)) - np.repeat(b_2.reshape([1,-1]),train_T,axis=0)\n",
    "Sig_2 = np.mean(\\\n",
    "                np.matmul(\\\n",
    "                          np.reshape(tmp,[-1,s_dim,1]),\\\n",
    "                          np.reshape(tmp,[-1,1,s_dim])\\\n",
    "                         ),axis=0\\\n",
    "               )\n",
    "\n",
    "o_t_train = train_data[:,2*s_dim:3*s_dim]\n",
    "sumOtSt = np.sum(\\\n",
    "                 np.matmul(\\\n",
    "                           np.reshape(o_t_train,[-1,o_dim,1]),\\\n",
    "                           np.reshape(s_t_train,[-1,1,s_dim])\\\n",
    "                          ),axis=0\\\n",
    "                )\n",
    "sumStSt = np.sum(\\\n",
    "                 np.matmul(\\\n",
    "                           np.reshape(s_t_train,[-1,s_dim,1]),\\\n",
    "                           np.reshape(s_t_train,[-1,1,s_dim])\\\n",
    "                          ),axis=0\\\n",
    "                )\n",
    "sumOt = np.transpose(np.sum(o_t_train,axis=0,keepdims=True))\n",
    "\n",
    "A_3 = np.matmul(\\\n",
    "                sumOtSt - (np.matmul(sumOt, np.transpose(sumSt)) / train_T),\\\n",
    "                np.linalg.inv(\\\n",
    "                              sumStSt - (np.matmul(sumSt, np.transpose(sumSt)) / train_T)\n",
    "                             )\\\n",
    "               )\n",
    "b_3 = (sumOt - np.matmul(A_3, sumSt)) / train_T\n",
    "\n",
    "tmp = o_t_train - np.matmul(s_t_train, np.transpose(A_3)) - np.repeat(b_3.reshape([1,-1]),train_T,axis=0)\n",
    "Sig_3 = np.mean(\\\n",
    "                np.matmul(\\\n",
    "                          np.reshape(tmp,[-1,o_dim,1]),\\\n",
    "                          np.reshape(tmp,[-1,1,o_dim])\\\n",
    "                         ),axis=0\\\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf_orig = KalmanFilter(\\\n",
    "                       initial_state_mean =\\\n",
    "                           np.matmul(A_2, np.transpose(test_data[0,:s_dim])) + b_2.reshape(-1),\\\n",
    "                       initial_state_covariance = Sig_2,\\\n",
    "                       transition_matrices = A_2, \\\n",
    "                       transition_covariance = Sig_2, \\\n",
    "                       transition_offsets = np.transpose(b_2.reshape(-1)),\\\n",
    "                       observation_matrices = A_3,\\\n",
    "                       observation_covariance = Sig_3,\\\n",
    "                       observation_offsets = np.transpose(b_3.reshape(-1))\\\n",
    "                      )\n",
    "measurements = test_data[:,2*s_dim:]\n",
    "(est_s_t, est_s_t_covariances) = kf_orig.filter(measurements)\n",
    "print(np.mean(np.linalg.norm(est_s_t - test_data[:, s_dim : 2*s_dim] , axis = 1)), end = '')\n",
    "print(' / ', end = '')\n",
    "print(np.mean(np.linalg.norm(test_data[:, s_dim : 2*s_dim], axis = 1)))\n",
    "print('mean consecutive diff: ', end='')\n",
    "print(np.mean(np.linalg.norm(test_data[1:, s_dim : 2*s_dim] - test_data[:-1, s_dim : 2*s_dim], axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "MaxIter = 100\n",
    "train_T = train_data.shape[0]\n",
    "s_t_minus_1_train = train_data[:,:s_dim]\n",
    "s_t_train = train_data[:,s_dim:2*s_dim]\n",
    "\n",
    "sumStSt_1 = np.sum(\\\n",
    "                   np.matmul(\\\n",
    "                             np.reshape(s_t_train, [-1,s_dim,1]),\\\n",
    "                             np.reshape(s_t_minus_1_train, [-1,1,s_dim])\\\n",
    "                            ),axis=0\\\n",
    "                  )\n",
    "sumSt_1 = np.transpose(np.sum(s_t_minus_1_train, axis=0, keepdims=True))\n",
    "sumSt = np.transpose(np.sum(s_t_train,axis=0,keepdims=True))\n",
    "invsumSt_1St_1 = np.linalg.inv(\\\n",
    "                               np.sum(\\\n",
    "                                      np.matmul(\\\n",
    "                                                np.reshape(s_t_minus_1_train, [-1,s_dim,1]),\\\n",
    "                                                np.reshape(s_t_minus_1_train, [-1,1,s_dim])\\\n",
    "                                               ),axis=0\\\n",
    "                                     )\\\n",
    "                              )\n",
    "\n",
    "A_2 = np.eye(s_dim)\n",
    "b_2 = np.zeros([s_dim,1])\n",
    "for iter in range(MaxIter):\n",
    "    prev_A_2 = A_2\n",
    "    prev_b_2 = b_2\n",
    "    A_2 = np.matmul(\\\n",
    "                    sumStSt_1 - np.matmul(b_2, np.transpose(sumSt_1)),\\\n",
    "                    invsumSt_1St_1\\\n",
    "                   )\n",
    "    #b_2 = (sumSt - np.matmul(A_2, sumSt_1)) / train_T\n",
    "print(np.linalg.norm(A_2 - prev_A_2))\n",
    "print(np.linalg.norm(b_2 - prev_b_2))\n",
    "print('-------------------------')\n",
    "tmp = s_t_train - np.matmul(s_t_minus_1_train, np.transpose(A_2)) - np.repeat(b_2.reshape([1,-1]),train_T,axis=0)\n",
    "Sig_2 = np.mean(\\\n",
    "                np.matmul(\\\n",
    "                          np.reshape(tmp,[-1,s_dim,1]),\\\n",
    "                          np.reshape(tmp,[-1,1,s_dim])\\\n",
    "                         ),axis=0\\\n",
    "               )\n",
    "\n",
    "o_t_train = train_data[:,2*s_dim:3*s_dim]\n",
    "sumOtSt = np.sum(\\\n",
    "                 np.matmul(\\\n",
    "                           np.reshape(o_t_train,[-1,o_dim,1]),\\\n",
    "                           np.reshape(s_t_train,[-1,1,s_dim])\\\n",
    "                          ),axis=0\\\n",
    "                )\n",
    "invsumStSt = np.linalg.inv(\\\n",
    "                           np.sum(\\\n",
    "                                  np.matmul(\\\n",
    "                                            np.reshape(s_t_train,[-1,s_dim,1]),\\\n",
    "                                            np.reshape(s_t_train,[-1,1,s_dim])\\\n",
    "                                           ),axis=0\\\n",
    "                                 )\\\n",
    "                          )\n",
    "sumOt = np.transpose(np.sum(o_t_train,axis=0,keepdims=True))\n",
    "A_3 = np.eye(o_dim, s_dim)\n",
    "b_3 = np.zeros([o_dim,1])\n",
    "for iter in range(MaxIter):\n",
    "    prev_A_3 = A_3\n",
    "    prev_b_3 = b_3\n",
    "    A_3 = np.matmul(\\\n",
    "                    sumOtSt - np.matmul(b_3, np.transpose(sumSt)),\\\n",
    "                    invsumStSt\\\n",
    "                   )\n",
    "    #b_3 = (sumOt - np.matmul(A_3, sumSt)) / train_T\n",
    "print(np.linalg.norm(A_3 - prev_A_3))\n",
    "print(np.linalg.norm(b_3 - prev_b_3))\n",
    "print('+++++++++++++++++++++++++')\n",
    "tmp = o_t_train - np.matmul(s_t_train, np.transpose(A_3)) - np.repeat(b_3.reshape([1,-1]),train_T,axis=0)\n",
    "Sig_3 = np.mean(\\\n",
    "                np.matmul(\\\n",
    "                          np.reshape(tmp,[-1,o_dim,1]),\\\n",
    "                          np.reshape(tmp,[-1,1,o_dim])\\\n",
    "                         ),axis=0\\\n",
    "               )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "MaxIter = 100\n",
    "train_T = train_data.shape[0]\n",
    "s_t_minus_1_train = train_data[:,:s_dim]\n",
    "s_t_train = train_data[:,s_dim:2*s_dim]\n",
    "meanStSt_1 = np.mean(\\\n",
    "                   np.matmul(\\\n",
    "                             np.reshape(s_t_train, [-1,s_dim,1]),\\\n",
    "                             np.reshape(s_t_minus_1_train, [-1,1,s_dim])\\\n",
    "                            ),axis=0\\\n",
    "                  )\n",
    "meanSt_1 = np.transpose(np.mean(s_t_minus_1_train, axis=0, keepdims=True))\n",
    "meanSt = np.transpose(np.mean(s_t_train,axis=0,keepdims=True))\n",
    "invmeanSt_1St_1 = np.linalg.inv(\\\n",
    "                               np.mean(\\\n",
    "                                      np.matmul(\\\n",
    "                                                np.reshape(s_t_minus_1_train, [-1,s_dim,1]),\\\n",
    "                                                np.reshape(s_t_minus_1_train, [-1,1,s_dim])\\\n",
    "                                               ),axis=0\\\n",
    "                                     )\\\n",
    "                              )\n",
    "A_2 = np.eye(s_dim)\n",
    "b_2 = np.zeros([s_dim,1])\n",
    "for iter in range(MaxIter):\n",
    "    prev_A_2 = A_2\n",
    "    prev_b_2 = b_2\n",
    "    A_2 = np.matmul(\\\n",
    "                    meanStSt_1 - np.matmul(b_2, np.transpose(meanSt_1)),\\\n",
    "                    invmeanSt_1St_1\\\n",
    "                   )\n",
    "    b_2 = meanSt - np.matmul(A_2, meanSt_1)\n",
    "    #print(np.linalg.norm(A_2 - prev_A_2))\n",
    "    #print(np.linalg.norm(b_2 - prev_b_2))\n",
    "    #print('-------------------------')\n",
    "tmp = s_t_train - np.matmul(s_t_minus_1_train, np.transpose(A_2)) - np.repeat(b_2.reshape([1,-1]),train_T,axis=0)\n",
    "Sig_2 = np.mean(\\\n",
    "                np.matmul(\\\n",
    "                          np.reshape(tmp,[-1,s_dim,1]),\\\n",
    "                          np.reshape(tmp,[-1,1,s_dim])\\\n",
    "                         ),axis=0\\\n",
    "               )\n",
    "o_t_train = train_data[:,2*s_dim:3*s_dim]\n",
    "meanOtSt = np.mean(\\\n",
    "                 np.matmul(\\\n",
    "                           np.reshape(o_t_train,[-1,o_dim,1]),\\\n",
    "                           np.reshape(s_t_train,[-1,1,s_dim])\\\n",
    "                          ),axis=0\\\n",
    "                )\n",
    "invmeanStSt = np.linalg.inv(\\\n",
    "                           np.mean(\\\n",
    "                                  np.matmul(\\\n",
    "                                            np.reshape(s_t_train,[-1,s_dim,1]),\\\n",
    "                                            np.reshape(s_t_train,[-1,1,s_dim])\\\n",
    "                                           ),axis=0\\\n",
    "                                 )\\\n",
    "                          )\n",
    "meanOt = np.transpose(np.mean(o_t_train,axis=0,keepdims=True))\n",
    "A_3 = np.eye(o_dim, s_dim)\n",
    "b_3 = np.zeros([o_dim,1])\n",
    "for iter in range(MaxIter):\n",
    "    prev_A_3 = A_3\n",
    "    prev_b_3 = b_3\n",
    "    A_3 = np.matmul(\\\n",
    "                    meanOtSt - np.matmul(b_3, np.transpose(meanSt)),\\\n",
    "                    invmeanStSt\\\n",
    "                   )\n",
    "    b_3 = meanOt - np.matmul(A_3, meanSt)\n",
    "    #print(np.linalg.norm(A_3 - prev_A_3))\n",
    "    #print(np.linalg.norm(b_3 - prev_b_3))\n",
    "    #print('+++++++++++++++++++++++++')\n",
    "tmp = o_t_train - np.matmul(s_t_train, np.transpose(A_3)) - np.repeat(b_3.reshape([1,-1]),train_T,axis=0)\n",
    "Sig_3 = np.mean(\\\n",
    "                np.matmul(\\\n",
    "                          np.reshape(tmp,[-1,o_dim,1]),\\\n",
    "                          np.reshape(tmp,[-1,1,o_dim])\\\n",
    "                         ),axis=0\\\n",
    "               )\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
