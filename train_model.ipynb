{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model import Model\n",
    "import os\n",
    "from pykalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data.txt') as f:\n",
    "    first = f.readline()\n",
    "    first = first.strip('\\n')\n",
    "    temp = first.split(' ')\n",
    "    T = int(temp[0])\n",
    "    o_dim = int(temp[1])\n",
    "    s_dim = int(temp[2])\n",
    "    o_matrix = np.zeros((T, o_dim), np.float32)\n",
    "    for i in range(T):\n",
    "        temp = f.readline().strip('\\n').split(' ')\n",
    "        for j in range(s_dim):\n",
    "            o_matrix[i,j] = float(temp[j])\n",
    "    s_matrix = np.zeros((T, s_dim), np.float32)\n",
    "    for i in range(T):\n",
    "        temp = f.readline().strip('\\n').split(' ')\n",
    "        for j in range(o_dim):\n",
    "            s_matrix[i,j] = float(temp[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T_train = 1000\n",
    "train_data = np.zeros((T_train, 3*s_dim), np.float32)\n",
    "for i in range(T_train):\n",
    "    train_data[i, :] = np.concatenate((s_matrix[i, :], s_matrix[i+1, :], o_matrix[i+1, :]), axis=0)\n",
    "    \n",
    "T_test = 1000\n",
    "test_data = np.zeros((T_test, 3*s_dim), np.float32)\n",
    "for i in range(T_test):\n",
    "    test_data[i, :] = np.concatenate((s_matrix[T_train + i, :], s_matrix[T_train + 1 + i, :], o_matrix[T_train + 1 + i, :]),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_T = train_data.shape[0]\n",
    "s_t_minus_1_train = train_data[:,:s_dim]\n",
    "s_t_train = train_data[:,s_dim:2*s_dim]\n",
    "\n",
    "sumStSt_1 = np.sum(\\\n",
    "                   np.matmul(\\\n",
    "                             np.reshape(s_t_train, [-1,s_dim,1]),\\\n",
    "                             np.reshape(s_t_minus_1_train, [-1,1,s_dim])\\\n",
    "                            ),axis=0\\\n",
    "                  )\n",
    "sumSt_1 = np.transpose(np.sum(s_t_minus_1_train, axis=0, keepdims=True))\n",
    "sumSt = np.transpose(np.sum(s_t_train,axis=0,keepdims=True))\n",
    "sumSt_1St_1 =np.sum(\\\n",
    "                    np.matmul(\\\n",
    "                              np.reshape(s_t_minus_1_train, [-1,s_dim,1]),\\\n",
    "                              np.reshape(s_t_minus_1_train, [-1,1,s_dim])\\\n",
    "                             ),axis=0\\\n",
    "                   )\n",
    "\n",
    "A_2 = np.matmul(\\\n",
    "                sumStSt_1 - (np.matmul(sumSt, np.transpose(sumSt_1)) / train_T),\\\n",
    "                np.linalg.inv(\\\n",
    "                              sumSt_1St_1 - (np.matmul(sumSt_1, np.transpose(sumSt_1)) / train_T)\n",
    "                             )\\\n",
    "               )\n",
    "b_2 = (sumSt - np.matmul(A_2, sumSt_1)) / train_T\n",
    "\n",
    "tmp = s_t_train - np.matmul(s_t_minus_1_train, np.transpose(A_2)) - np.repeat(b_2.reshape([1,-1]),train_T,axis=0)\n",
    "Sig_2 = np.mean(\\\n",
    "                np.matmul(\\\n",
    "                          np.reshape(tmp,[-1,s_dim,1]),\\\n",
    "                          np.reshape(tmp,[-1,1,s_dim])\\\n",
    "                         ),axis=0\\\n",
    "               )\n",
    "\n",
    "o_t_train = train_data[:,2*s_dim:3*s_dim]\n",
    "sumOtSt = np.sum(\\\n",
    "                 np.matmul(\\\n",
    "                           np.reshape(o_t_train,[-1,o_dim,1]),\\\n",
    "                           np.reshape(s_t_train,[-1,1,s_dim])\\\n",
    "                          ),axis=0\\\n",
    "                )\n",
    "sumStSt = np.sum(\\\n",
    "                 np.matmul(\\\n",
    "                           np.reshape(s_t_train,[-1,s_dim,1]),\\\n",
    "                           np.reshape(s_t_train,[-1,1,s_dim])\\\n",
    "                          ),axis=0\\\n",
    "                )\n",
    "sumOt = np.transpose(np.sum(o_t_train,axis=0,keepdims=True))\n",
    "\n",
    "A_3 = np.matmul(\\\n",
    "                sumOtSt - (np.matmul(sumOt, np.transpose(sumSt)) / train_T),\\\n",
    "                np.linalg.inv(\\\n",
    "                              sumStSt - (np.matmul(sumSt, np.transpose(sumSt)) / train_T)\n",
    "                             )\\\n",
    "               )\n",
    "b_3 = (sumOt - np.matmul(A_3, sumSt)) / train_T\n",
    "\n",
    "tmp = o_t_train - np.matmul(s_t_train, np.transpose(A_3)) - np.repeat(b_3.reshape([1,-1]),train_T,axis=0)\n",
    "Sig_3 = np.mean(\\\n",
    "                np.matmul(\\\n",
    "                          np.reshape(tmp,[-1,o_dim,1]),\\\n",
    "                          np.reshape(tmp,[-1,1,o_dim])\\\n",
    "                         ),axis=0\\\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf_orig = KalmanFilter(\\\n",
    "                       initial_state_mean =\\\n",
    "                           np.matmul(A_2, np.transpose(test_data[0,:s_dim])) + b_2.reshape(-1),\\\n",
    "                       initial_state_covariance = Sig_2,\\\n",
    "                       transition_matrices = A_2, \\\n",
    "                       transition_covariance = Sig_2, \\\n",
    "                       transition_offsets = np.transpose(b_2.reshape(-1)),\\\n",
    "                       observation_matrices = A_3,\\\n",
    "                       observation_covariance = Sig_3,\\\n",
    "                       observation_offsets = np.transpose(b_3.reshape(-1))\\\n",
    "                      )\n",
    "measurements = test_data[:,2*s_dim:]\n",
    "(est_s_t, est_s_t_covariances) = kf_orig.filter(measurements)\n",
    "print(np.mean(np.linalg.norm(est_s_t - test_data[:, s_dim : 2*s_dim] , axis = 1)), end = '')\n",
    "print(' / ', end = '')\n",
    "print(np.mean(np.linalg.norm(test_data[:, s_dim : 2*s_dim], axis = 1)))\n",
    "print('mean consecutive diff: ', end='')\n",
    "print(np.mean(np.linalg.norm(test_data[1:, s_dim : 2*s_dim] - test_data[:-1, s_dim : 2*s_dim], axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, train, test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "    def random_batch(self, batch_size):\n",
    "        index = np.random.choice(np.arange(len(self.train)),batch_size, False)\n",
    "        return self.train[index,:]\n",
    "dataset = Dataset(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir = './log/'\n",
    "os.popen('rm '+log_dir+'*')\n",
    "h_dim = 10\n",
    "minibatch_size = 128\n",
    "model = Model(s_dim, h_dim, minibatch_size, 1e-4, log_dir)\n",
    "iteration = 300\n",
    "for epoch in range(100):\n",
    "    reconstruction_loss_train, likelihood_train, classify_loss_train = 0., 0., 0.\n",
    "    global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "    # in each epoch 500 iterations\n",
    "    for i in range(iteration):\n",
    "        reconstruction_loss_value, likelihood_value, classify_loss_value, summary = \\\n",
    "                model.update_params(dataset.random_batch(minibatch_size))\n",
    "            \n",
    "        reconstruction_loss_train += reconstruction_loss_value\n",
    "        likelihood_train += likelihood_value\n",
    "        classify_loss_train += classify_loss_value\n",
    "        model.train_writer.add_summary(summary, global_step.eval(model.sess))\n",
    "    \n",
    "    reconstruction_loss_train = reconstruction_loss_train / (iteration)\n",
    "    likelihood_train = -likelihood_train / (iteration)\n",
    "    classify_loss_train = classify_loss_train / (iteration)\n",
    "    \n",
    "\n",
    "    print(\"step: {},\\trecons loss: {:.4f},\\tlikelihood: {:.4f},\\tclass loss: {:.4f}\".format(global_step.eval(model.sess),\n",
    "            reconstruction_loss_train, likelihood_train, classify_loss_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_s_p = np.asarray(model.sess.run([model.s_t_p], {model.input_tensor: train_data[train_data.shape[0]-2 : ,:]}))[0][1,:]\n",
    "\n",
    "a_2, b_2, sig_2, a_3, b_3, sig_3 = model.sess.run([model.a_2, model.b_2, model.sigma_2,\\\n",
    "                                                    model.a_3, model.b_3, model.sigma_3],\\\n",
    "                                                   {model.input_tensor: train_data}\\\n",
    "                                                  )\n",
    "kf = KalmanFilter(initial_state_mean = np.transpose(np.matmul(last_s_p,a_2) + b_2), \\\n",
    "                  initial_state_covariance = sig_2, \\\n",
    "                  transition_matrices = np.transpose(a_2), \\\n",
    "                  transition_offsets = b_2,\n",
    "                  transition_covariance = sig_2, \\\n",
    "                  observation_matrices = np.transpose(a_3),\\\n",
    "                  observation_offsets = b_3,\n",
    "                  observation_covariance = sig_3)\n",
    "est_o_t_p = model.sess.run(model.o_t_p, {model.input_tensor: test_data})\n",
    "measurements = np.asarray(est_o_t_p)\n",
    "(est_s_t_p, est_s_t_p_covariances) = kf.filter(measurements)\n",
    "est_s_t = model.decode_s_t_p(est_s_t_p)\n",
    "print(np.mean(np.linalg.norm(est_s_t - test_data[:, s_dim : 2*s_dim] , axis = 1)), end = '')\n",
    "print(' / ', end = '')\n",
    "print(np.mean(np.linalg.norm(test_data[:, s_dim : 2*s_dim], axis = 1)))\n",
    "print('mean consecutive diff: ', end='')\n",
    "print(np.mean(np.linalg.norm(test_data[1:, s_dim : 2*s_dim] - test_data[:-1, s_dim : 2*s_dim], axis = 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
